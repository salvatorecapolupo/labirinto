<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>RL Labirinto</title>
  <style>
    body { font-family: monospace; background: #111; color: #0f0; margin: 0; padding: 0; display: flex; flex-direction: column; align-items: center; }
    #maze { display: grid; grid-template-columns: repeat(5, 40px); grid-template-rows: repeat(5, 40px); margin: 20px; }
    .cell { width: 40px; height: 40px; border: 1px solid #0f0; display: flex; align-items: center; justify-content: center; }
    .wall { background: #0f0; color: #111; }
    .agent { background: #0f0; color: #111; font-weight: bold; }
    .goal { background: #f00; color: #fff; }
    button { background: #0f0; color: #111; border: none; padding: 10px; margin: 5px; cursor: pointer; }
    .panel { display: none; max-width: 600px; padding: 20px; border: 1px solid #0f0; margin-bottom: 10px; }
    .panel.active { display: block; }
    .controls { display: flex; justify-content: space-between; max-width: 600px; width: 100%; }
  </style>
</head>
<body>
  <h1>Agente IA nel Labirinto</h1>
  <div id="maze"></div>
  <button onclick="train()">Allena Agente</button>
  <button onclick="runAgent()">Esegui Agente</button>
  <div class="panel active" id="panel0">
    <h2>1. Definizione del problema</h2>
    <p>L'agente si trova in un labirinto 5x5 e deve imparare a raggiungere l'uscita muovendosi tra celle libere ed evitando i muri.</p>
  </div>
  <div class="panel" id="panel1">
    <h2>2. Reinforcement Learning</h2>
    <p>Utilizziamo il Q-learning: l'agente impara da prove ed errori aggiornando una tabella Q che assegna valore a ogni azione possibile in ogni stato.</p>
  </div>
  <div class="panel" id="panel2">
    <h2>3. Ricompense</h2>
    <p>L'agente riceve +100 per raggiungere l'obiettivo, -1 per ogni mossa e -5 se prova a muoversi contro un muro. Questo lo guida a trovare percorsi brevi ed efficaci.</p>
  </div>
  <div class="panel" id="panel3">
    <h2>4. Addestramento ed esecuzione</h2>
    <p>Durante l'addestramento esplora, mentre nell'esecuzione segue la politica ottimale appresa.</p>
  </div>
  <div class="controls">
    <button onclick="prevPanel()">&larr; Indietro</button>
    <button onclick="nextPanel()">Avanti &rarr;</button>
  </div>
  <script>
    const maze = [
      [0, 0, 1, 0, 0],
      [1, 0, 1, 0, 1],
      [0, 0, 0, 0, 0],
      [0, 1, 1, 1, 0],
      [0, 0, 0, 1, 0]
    ];
    const size = 5;
    const goal = [4, 4];
    let agent = [0, 0];
    let q = {};

    function stateKey([x, y]) {
      return `${x},${y}`;
    }

    function availableActions([x, y]) {
      const actions = [];
      if (x > 0 && maze[y][x - 1] === 0) actions.push([-1, 0]);
      if (x < size - 1 && maze[y][x + 1] === 0) actions.push([1, 0]);
      if (y > 0 && maze[y - 1][x] === 0) actions.push([0, -1]);
      if (y < size - 1 && maze[y + 1][x] === 0) actions.push([0, 1]);
      return actions;
    }

    function train(episodes = 1000, alpha = 0.1, gamma = 0.9, epsilon = 0.2) {
      for (let i = 0; i < episodes; i++) {
        let pos = [0, 0];
        while (true) {
          const key = stateKey(pos);
          q[key] = q[key] || {};
          const actions = availableActions(pos);
          const a = Math.random() < epsilon ? actions[Math.floor(Math.random() * actions.length)] : actions.reduce((best, a) => q[key][a] > (q[key][best] || 0) ? a : best, actions[0]);
          const next = [pos[0] + a[0], pos[1] + a[1]];
          const reward = (next[0] === goal[0] && next[1] === goal[1]) ? 100 : -1;
          const nextKey = stateKey(next);
          q[key][a] = (q[key][a] || 0) + alpha * (reward + gamma * Math.max(...Object.values(q[nextKey] || {})) - (q[key][a] || 0));
          pos = next;
          if (pos[0] === goal[0] && pos[1] === goal[1]) break;
        }
      }
      alert("Addestramento completato!");
    }

    async function runAgent() {
      agent = [0, 0];
      renderMaze();
      while (agent[0] !== goal[0] || agent[1] !== goal[1]) {
        await new Promise(r => setTimeout(r, 300));
        const actions = q[stateKey(agent)];
        const best = Object.entries(actions).reduce((a, b) => a[1] > b[1] ? a : b);
        const [dx, dy] = JSON.parse(`[${best[0]}]`);
        agent = [agent[0] + dx, agent[1] + dy];
        renderMaze();
      }
      alert("Obiettivo raggiunto!");
    }

    function renderMaze() {
      const mazeEl = document.getElementById("maze");
      mazeEl.innerHTML = "";
      for (let y = 0; y < size; y++) {
        for (let x = 0; x < size; x++) {
          const div = document.createElement("div");
          div.className = "cell";
          if (maze[y][x] === 1) div.classList.add("wall");
          if (x === agent[0] && y === agent[1]) div.classList.add("agent");
          if (x === goal[0] && y === goal[1]) div.classList.add("goal");
          mazeEl.appendChild(div);
        }
      }
    }

    renderMaze();

    let panelIndex = 0;
    function showPanel(index) {
      document.querySelectorAll('.panel').forEach((el, i) => el.classList.toggle('active', i === index));
    }
    function nextPanel() {
      if (panelIndex < 3) showPanel(++panelIndex);
    }
    function prevPanel() {
      if (panelIndex > 0) showPanel(--panelIndex);
    }
  </script>
</body>
</html>
